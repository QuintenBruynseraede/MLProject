\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{longtable}
\usepackage[numbers]{natbib}
\author{Ignace Bleukx AND Quinten Bruynseraede}
\title{Machine Learning Project: part 1}
\begin{document}
\maketitle

\section{Literature Review}
In this first assignment we try to combine basic principles from game theory with the work concerning multi-agent reinforcement learning. Most literature included in this literature review will therefore more of less fall into one of these categories. First we give an overview of the relevant literature. Afterwards, we give a detailed list of the contributions for each paper.

\citet{mas} introduces elementary concepts from game theory. \citet{phdthesis} introduces basic concepts from multi-agent systems, and explains how reinforcement learning algorithms can be used to reach equilibriums in simple games. Replicator dynamics are introduced to model evolutionary concepts in multi-agent systems. \citet{phdthesis} also introduces lenient reinforcement learning to overcome difficulties when bad initial exploration leads to convergence to wrong equilibria.

We use the game-theoretic reinforcement learning framework OpenSpiel for all experiments. The practical details are outlined in \citet{lanctot2019openspiel}. Details about solving the Prisoner's Dilemma using reinforcement learning algorithms are found in \citet{rlforpd}.

To implement the Lenient Frequency Adjusted Q-Learning, we used \citet{evoldynamics} and \citet{extrepl}.



\bigskip
\begin{longtable}{|p{4cm}|p{9cm}|}
\hline 
Article & Contribution \\ 
\hline 
\hline
Multi-agent systems: Algorithmic, Game-Theoretic,and Logical Foundations, \citet{mas} & This paper provides a thorough explaination of the different aspect of game theory, including different types of equilibria. These concepts are of importance to us since we will investigate whether or not our learning algorithms converge to one of these equilibria. Furthermore, the paper provides a detailed description of different types of games, such as cooperative games and non-cooperative games, as well as the notion of games in normal form.   \\ 
\hline 
Multi-agent learning dynamics, \citet{phdthesis} &  This thesis on multi agent learning dynamics provides essential information about different game theory aspects. Not all sections are relevant for our initial research on matrix games. Mainly section 2.3 on evolutionary game theory and chapter 3 are relevant. In this last chapter, the replicator dynamics of many matrix games are investigated and explained very clearly. In this chapter we find an example of the learning pattern we would like to observe with our application of different learning algorithms.   \\
\hline 
OpenSpiel: A Framework for Reinforcement Learning in Games, \citet{lanctot2019openspiel} & The paper provides the documentation of the OpenSpiel framework. All aspects of the library are explained, from installation to implemented algorithms and games. Many design choices of the framework are clarified which helps to understand the philosophy behind the framework. In the paper, the game theory aspects are briefly touched upon, as well as important concepts of the implemented learning algorithms. This paper is of very much importance to us as we will use (and potetially extend) the OpenSpiel framework for this assignement. \\ 
\hline  
Reinforcement learning produces dominant strategies for the Iterated Prisonerâ€™s Dilemma, \citet{rlforpd} & 
This document contains a detailed description of the prisoners dilemma. Since this is one of the matrix games we will examine in the first part of the assignement, this belongs to the relevant lecture on this list. Furhermore, some examples of parameters for the training algorithms are given, which will help to produce meaningfull results when training the learning algorithms of choice.\\ 
\hline 
The replicator equation on graphs, \citet{Ohtsuki2006TheRE} & The paper provides an insight on the visualization of the replicator dynamics using phase, as well as some examples relevant to our research. These examples include the prisoners dilemma and biased rock-paper-scissors.\\
\hline
Analyzing Reinforcement Learning algorithmsusing Evolutionary Game Theory, \citet{bloembergenmaster} & This thesis provides a rich source of information on the reinforcement learning branch for evolutionary game theory. Many algorithms are examined, some of which are available in OpenSpiel. The paper also contains the exact parameter settings used to achieve the presented results. These paramters can be used by our agents to reproduce favorable results of the paper. \\
\hline
Evolutionary Dynamics of Multi-Agent Learning:A Survey, \citet{evoldynamics} & Like other papers, this document provides a basic knowledge of game theory, as well as reinforcement learning. For our research, mainly the part about lenient FAQ-learning as a way to increase the robustness of Q-learning, is important. FAQ-learning is able to recover from bad exploration in the start of the run, while normal Q-learning is sometimes not. \\
\hline
Extended Replicator Dynamics as a Key to Reinforcement Learning in Multi-agent Systems, \citet{extrepl} & To model stochastic policies, populations of players are used. These populations can be described using evolutionary concepts, such as selection and mutation. This paper explains the transition from regular to evolutionary game theory. We received insight on the dynamics of a population through the central notion of replicator dynamics. These selection mechanisms can be extended with mutation, based on the Boltzmann mechanism. To overcome converge to suboptimal equilibria, lenience towards mistakes is introduced in this paper.
\\ 
\hline
\end{longtable} 

\section{Independent learning}
%TODO: learn 2 agents on all games, show convergence. Do the learning algorithms converge to Nash equilibria. Are these Pareto optimal?
\section{Dynamics of learning}


\bibliography{lit}{}
\bibliographystyle{plainnat}
\end{document}